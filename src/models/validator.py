"""
Rolling Origin Cross-Validation
================================

Implements rolling origin (time-series) cross-validation.
Ensures proper temporal validation without data leakage.

Usage:
    from src.models.validator import RollingOriginValidator
    
    validator = RollingOriginValidator(n_splits=5, test_size_days=30)
    for train_idx, test_idx in validator.split(df):
        # Train and evaluate
"""

import pandas as pd
import numpy as np
from typing import Iterator, Tuple, Optional, List, Dict
from datetime import timedelta

from src.logger import get_logger

logger = get_logger(__name__)


class RollingOriginValidator:
    """
    Rolling origin cross-validation for time series.
    
    Ensures temporal ordering: train data always comes before test data.
    Supports gap between train and test to simulate real forecasting scenarios.
    """
    
    def __init__(
        self,
        n_splits: int = 5,
        test_size_days: int = 30,
        gap_days: int = 1,
        min_train_days: int = 365
    ):
        """
        Initialize rolling origin validator.
        
        Args:
            n_splits: Number of cross-validation splits
            test_size_days: Size of test set in days
            gap_days: Gap between train and test sets in days
            min_train_days: Minimum training period in days
        """
        self.n_splits = n_splits
        self.test_size_days = test_size_days
        self.gap_days = gap_days
        self.min_train_days = min_train_days
        
        logger.info(f"Rolling origin validator initialized: {n_splits} splits, "
                   f"test_size={test_size_days}d, gap={gap_days}d, min_train={min_train_days}d")
    
    def split(
        self,
        df: pd.DataFrame
    ) -> Iterator[Tuple[pd.DatetimeIndex, pd.DatetimeIndex]]:
        """
        Generate train/test splits.
        
        Args:
            df: DataFrame with DatetimeIndex
        
        Yields:
            Tuple of (train_index, test_index)
        """
        if not isinstance(df.index, pd.DatetimeIndex):
            raise ValueError("DataFrame must have DatetimeIndex")
        
        logger.info(f"Generating {self.n_splits} rolling origin splits")
        
        # Calculate split points
        data_start = df.index.min()
        data_end = df.index.max()
        total_days = (data_end - data_start).days
        
        logger.info(f"Data range: {data_start} to {data_end} ({total_days} days)")
        
        # Calculate minimum required days
        min_required_days = self.min_train_days + self.gap_days + self.test_size_days
        
        if total_days < min_required_days:
            raise ValueError(
                f"Insufficient data: {total_days} days available, "
                f"{min_required_days} days required"
            )
        
        # Calculate available days for splits
        available_days = total_days - self.min_train_days - self.gap_days - self.test_size_days
        
        if available_days < 0:
            raise ValueError("Not enough data for even one split")
        
        # Calculate step size between splits
        if self.n_splits > 1:
            step_days = available_days / (self.n_splits - 1)
        else:
            step_days = 0
        
        # Generate splits
        for split_idx in range(self.n_splits):
            # Calculate train end
            train_end = data_start + timedelta(
                days=self.min_train_days + int(split_idx * step_days)
            )
            
            # Calculate test start and end
            test_start = train_end + timedelta(days=self.gap_days)
            test_end = test_start + timedelta(days=self.test_size_days)
            
            # Ensure test_end doesn't exceed data_end
            if test_end > data_end:
                test_end = data_end
            
            # Get indices
            train_mask = (df.index >= data_start) & (df.index <= train_end)
            test_mask = (df.index >= test_start) & (df.index <= test_end)
            
            train_index = df.index[train_mask]
            test_index = df.index[test_mask]
            
            logger.info(f"Split {split_idx + 1}/{self.n_splits}:")
            logger.info(f"  Train: {train_index.min()} to {train_index.max()} ({len(train_index)} samples)")
            logger.info(f"  Test:  {test_index.min()} to {test_index.max()} ({len(test_index)} samples)")
            
            yield train_index, test_index
    
    def validate_model(
        self,
        df: pd.DataFrame,
        features: List[str],
        target: str,
        model_class,
        model_params: Optional[Dict] = None,
        metrics: Optional[List[str]] = None
    ) -> pd.DataFrame:
        """
        Perform rolling origin cross-validation for a model.
        
        Args:
            df: DataFrame with features and target
            features: List of feature column names
            target: Target column name
            model_class: Model class to instantiate
            model_params: Parameters for model initialization
            metrics: List of metrics to compute
        
        Returns:
            DataFrame with validation results for each split
        """
        if metrics is None:
            metrics = ['rmse', 'mae', 'mape', 'r2']
        
        if model_params is None:
            model_params = {}
        
        logger.info("Starting rolling origin cross-validation")
        
        results = []
        
        for split_idx, (train_idx, test_idx) in enumerate(self.split(df)):
            logger.info(f"Validating split {split_idx + 1}/{self.n_splits}")
            
            # Prepare data
            X_train = df.loc[train_idx, features]
            y_train = df.loc[train_idx, target]
            X_test = df.loc[test_idx, features]
            y_test = df.loc[test_idx, target]
            
            # Remove rows with missing values
            train_valid = ~(X_train.isna().any(axis=1) | y_train.isna())
            test_valid = ~(X_test.isna().any(axis=1) | y_test.isna())
            
            X_train = X_train[train_valid]
            y_train = y_train[train_valid]
            X_test = X_test[test_valid]
            y_test = y_test[test_valid]
            
            if len(X_train) == 0 or len(X_test) == 0:
                logger.warning(f"Split {split_idx + 1} has no valid data, skipping")
                continue
            
            # Train model
            model = model_class(**model_params)
            model.fit(X_train, y_train)
            
            # Evaluate
            split_metrics = model.evaluate(X_test, y_test, metrics=metrics)
            split_metrics['split'] = split_idx + 1
            split_metrics['train_size'] = len(X_train)
            split_metrics['test_size'] = len(X_test)
            split_metrics['train_start'] = train_idx.min()
            split_metrics['train_end'] = train_idx.max()
            split_metrics['test_start'] = test_idx.min()
            split_metrics['test_end'] = test_idx.max()
            
            results.append(split_metrics)
        
        results_df = pd.DataFrame(results)
        
        # Log summary
        logger.info("Cross-validation complete")
        logger.info("Summary statistics:")
        for metric in metrics:
            if metric in results_df.columns:
                mean_val = results_df[metric].mean()
                std_val = results_df[metric].std()
                logger.info(f"  {metric}: {mean_val:.4f} Â± {std_val:.4f}")
        
        return results_df


class ExpandingWindowValidator:
    """
    Expanding window cross-validation.
    
    Similar to rolling origin, but training window expands instead of sliding.
    """
    
    def __init__(
        self,
        n_splits: int = 5,
        test_size_days: int = 30,
        gap_days: int = 1,
        min_train_days: int = 365
    ):
        """
        Initialize expanding window validator.
        
        Args:
            n_splits: Number of cross-validation splits
            test_size_days: Size of test set in days
            gap_days: Gap between train and test sets in days
            min_train_days: Minimum training period in days
        """
        self.n_splits = n_splits
        self.test_size_days = test_size_days
        self.gap_days = gap_days
        self.min_train_days = min_train_days
        
        logger.info(f"Expanding window validator initialized: {n_splits} splits")
    
    def split(
        self,
        df: pd.DataFrame
    ) -> Iterator[Tuple[pd.DatetimeIndex, pd.DatetimeIndex]]:
        """
        Generate train/test splits with expanding window.
        
        Args:
            df: DataFrame with DatetimeIndex
        
        Yields:
            Tuple of (train_index, test_index)
        """
        if not isinstance(df.index, pd.DatetimeIndex):
            raise ValueError("DataFrame must have DatetimeIndex")
        
        logger.info(f"Generating {self.n_splits} expanding window splits")
        
        data_start = df.index.min()
        data_end = df.index.max()
        total_days = (data_end - data_start).days
        
        # Calculate available days for splits
        available_days = total_days - self.min_train_days - self.gap_days - self.test_size_days
        
        if available_days < 0:
            raise ValueError("Not enough data for even one split")
        
        # Calculate step size
        if self.n_splits > 1:
            step_days = available_days / (self.n_splits - 1)
        else:
            step_days = 0
        
        # Generate splits
        for split_idx in range(self.n_splits):
            # Train always starts from beginning (expanding window)
            train_start = data_start
            train_end = data_start + timedelta(
                days=self.min_train_days + int(split_idx * step_days)
            )
            
            # Test period
            test_start = train_end + timedelta(days=self.gap_days)
            test_end = test_start + timedelta(days=self.test_size_days)
            
            if test_end > data_end:
                test_end = data_end
            
            # Get indices
            train_mask = (df.index >= train_start) & (df.index <= train_end)
            test_mask = (df.index >= test_start) & (df.index <= test_end)
            
            train_index = df.index[train_mask]
            test_index = df.index[test_mask]
            
            logger.info(f"Split {split_idx + 1}/{self.n_splits}:")
            logger.info(f"  Train: {train_index.min()} to {train_index.max()} ({len(train_index)} samples)")
            logger.info(f"  Test:  {test_index.min()} to {test_index.max()} ({len(test_index)} samples)")
            
            yield train_index, test_index
